{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttODwCFd8K0Q"
      },
      "source": [
        "# Access the MentalRiskEs data and interact with the server\n",
        "\n",
        "This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes2025/) evaluation campaign at IberLEF 2025.\n",
        "\n",
        "**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes2025/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.\n",
        "\n",
        "**NOTE 2**: Along the code, please replace \"URL\" by the URL server and \"TOKEN\" by your personal token.\n",
        "\n",
        "Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DJN0pXx8W3-"
      },
      "source": [
        "# Install CodeCarbon package\n",
        "Read the [documentation](https://mlco2.github.io/codecarbon/) about the library if necessary. Remember that we provide a [CodeCarbon notebook](https://colab.research.google.com/drive/1boavnGOir0urui8qktbZaOmOV2pS5cn6?usp=sharing) with the example in its specific use in our competition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdvPWyc6x9cV",
        "outputId": "cf639de5-3041-46ef-8d19-5049e02dc0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
            "[notice] To update, run: C:\\Users\\maxi.rodriguez\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# !pip install codecarbon\n",
        "# !pip install dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqyN-7TcXbL8"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sqih7m6tN4MT"
      },
      "outputs": [],
      "source": [
        "import requests, zipfile, io\n",
        "from requests.adapters import HTTPAdapter, Retry\n",
        "from typing import List, Dict\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "from codecarbon import EmissionsTracker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHGGrr3GXdIb"
      },
      "source": [
        "# Endpoints\n",
        "These URL addresses are necessary for the connection to the server.\n",
        "\n",
        "**IMPORTANT:** Replace \"URL\" by the URL server and \"TOKEN\" by your user token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AdQPl8lbOKsg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://s3-ceatic.ujaen.es:8036 c461869975ffb0a7ba8544ffdddf3b58\n"
          ]
        }
      ],
      "source": [
        "load_dotenv()\n",
        "URL = os.getenv(\"SERVER_URL\")\n",
        "TOKEN = os.getenv(\"ACCESS_TOKEN\")\n",
        "print(URL, TOKEN)\n",
        "\n",
        "# Download endpoints\n",
        "ENDPOINT_DOWNLOAD_TRIAL = URL+\"/{TASK}/download_trial/{TOKEN}\"\n",
        "ENDPOINT_DOWNLOAD_TRAIN = URL+\"/{TASK}/download_train/{TOKEN}\"\n",
        "\n",
        "# Trial endpoints\n",
        "ENDPOINT_GET_MESSAGES_TRIAL = URL+\"/{TASK}/getmessages_trial/{TOKEN}\"\n",
        "ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"/{TASK}/submit_trial/{TOKEN}/{RUN}\"\n",
        "\n",
        "# Test endpoints\n",
        "ENDPOINT_GET_MESSAGES = URL+\"/{TASK}/getmessages/{TOKEN}\"\n",
        "ENDPOINT_SUBMIT_DECISIONS = URL+\"/{TASK}/submit/{TOKEN}/{RUN}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHNiyxHR5AJ"
      },
      "source": [
        "# Download Data\n",
        "To download the data, you can make use of the **function defined in the following**.\n",
        "\n",
        "The following function download the trial data. To adapt it to download the train and test data, follow the instructions given in the [website of the competition](https://sites.google.com/view/mentalriskes2024/evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uaeh23C5R1lG"
      },
      "outputs": [],
      "source": [
        "def download_messages_trial(task: str, token: str):\n",
        "    \"\"\" Allows you to download the trial data of the task.\n",
        "        Args:\n",
        "          task (str): task from which the data is to be retrieved\n",
        "          token (str): authentication token\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.get(ENDPOINT_DOWNLOAD_TRIAL.format(TASK=task, TOKEN=token))\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
        "    else:\n",
        "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "      os.makedirs(\"./data/{task}/trial/\".format(task=task))\n",
        "      z.extractall(\"./data/{task}/trial/\".format(task=task))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v09j7ChSD6c-"
      },
      "outputs": [],
      "source": [
        "def download_messages_train(task: str, token: str):\n",
        "    \"\"\" Allows you to download the train data of the task.\n",
        "        Args:\n",
        "          task (str): task from which the data is to be retrieved\n",
        "          token (str): authentication token\n",
        "    \"\"\"\n",
        "    response = requests.get(ENDPOINT_DOWNLOAD_TRAIN.format(TASK=task, TOKEN=token))\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Train - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
        "    else:\n",
        "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "      os.makedirs(\"./data/{task}/train/\".format(task=task),exist_ok=True)\n",
        "      z.extractall(\"./data/{task}/train/\".format(task=task))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Required basic imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import string\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "\n",
        "# Imports for tokenizing and vectorizing data\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Imports for vectorized data pre-processing and classification models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import unicodedata\n",
        "\n",
        "def clear_tokens(tokens_list: list) -> None:\n",
        "    \"\"\" Removes punctuation symbols from the given tokens list \"\"\"\n",
        "    # Traverse the list backwards to avoid logic problems with pop() and indexes order\n",
        "    for i in range(len(tokens_list) - 1, -1, -1):\n",
        "        if tokens_list[i] in string.punctuation:\n",
        "            tokens_list.pop(i)\n",
        "    return\n",
        "\n",
        "def remove_emojis(keyword):\n",
        "    return re.sub(r\"[^\\w\\s,!?@#áéíóúÁÉÍÓÚñÑ]\", \"\", keyword)\n",
        "\n",
        "\n",
        "def user_document_to_input(messages_list, trained_vectorizer):\n",
        "    tokenizer = TweetTokenizer()\n",
        "    \n",
        "    # Remove emojis and tokenize\n",
        "    tokens = tokenizer.tokenize(remove_emojis(\" \".join(messages_list)))\n",
        "    clear_tokens(tokens)\n",
        "    \n",
        "    # Join tokens into a single document string\n",
        "    user_document = \" \".join(tokens)\n",
        "    \n",
        "    X = trained_vectorizer.transform([user_document])\n",
        "    return pd.DataFrame(X.toarray(), columns=trained_vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "# load the final models\n",
        "# --- tfidf vectorizer:\n",
        "vectorizer_tfidf_task1 = joblib.load(\"trained_models/tfidf_vectorizer_task1_emojis.joblib\")\n",
        "vectorizer_tfidf_task2 = joblib.load(\"trained_models/tfidf_vectorizer_task2_emojis.joblib\")\n",
        "\n",
        "# --- random forest baseline task 2\n",
        "model_rf_task2 = joblib.load(\"trained_models/RF_task2_emojis.joblib\")\n",
        "\n",
        "# --- svm baseline task 1\n",
        "model_svm_task1 = joblib.load(\"trained_models/SVM_task1_emojis.joblib\")\n",
        "\n",
        "# --- dedicate svms task 1\n",
        "topics = ['betting', 'trading', 'onlinegaming', 'lootboxes']\n",
        "svm_models_task1 = {\n",
        "    k: joblib.load(f\"trained_models/SVM_task1_{k}.joblib\") for k in topics\n",
        "}\n",
        "class Pipeline:\n",
        "    def predict(self, user_input):\n",
        "        rf_pred = model_rf_task2.predict(user_input)\n",
        "        return svm_models_task1[rf_pred[0]].predict(user_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIqRCv3OS3Bn"
      },
      "source": [
        "# Client Server\n",
        "This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests.\n",
        "\n",
        "**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0kONpltS2R9"
      },
      "outputs": [],
      "source": [
        "class Client_task1_2:\n",
        "    \"\"\" Client communicating with the official server.\n",
        "        Attributes:\n",
        "            token (str): authentication token\n",
        "            number_of_runs (int): number of systems. Must be 3 in order to advance to the next round.\n",
        "            tracker (EmissionsTracker): object to calculate the carbon footprint in prediction\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, task:str, token: str, number_of_runs: int, tracker: EmissionsTracker):\n",
        "        self.task = task\n",
        "        self.token = token\n",
        "        self.number_of_runs = number_of_runs\n",
        "        self.tracker = tracker\n",
        "        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy',\n",
        "                              'ram_energy','energy_consumed', 'cpu_count', 'gpu_count',\n",
        "                              'cpu_model', 'gpu_model', 'ram_total_size','country_iso_code']\n",
        "\n",
        "\n",
        "    def get_messages(self, retries: int, backoff: float) -> Dict:\n",
        "        \"\"\" Allows you to download the test data of the task by rounds.\n",
        "            Here a GET request is sent to the server to extract the data.\n",
        "            Args:\n",
        "              retries (int): number of calls on the server connection\n",
        "              backoff (float): time between retries\n",
        "        \"\"\"\n",
        "        session = requests.Session()\n",
        "        retries = Retry(\n",
        "                        total = retries,\n",
        "                        backoff_factor = backoff,\n",
        "                        status_forcelist = [500, 502, 503, 504]\n",
        "                        )\n",
        "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token)) # ENDPOINT\n",
        "\n",
        "        if response.status_code != 200:\n",
        "          print(\"GET - Task {} - Status Code {} - Error: {}\".format(self.task, str(response.status_code), str(response.text)))\n",
        "          return []\n",
        "        else:\n",
        "          return json.loads(response.content)\n",
        "\n",
        "    def submit_decission(self, messages: List[Dict], emissions: Dict, retries: int, backoff: float):\n",
        "        \"\"\" Allows you to submit the decisions of the task by rounds.\n",
        "            The POST requests are sent to the server to send predictions and carbon emission data\n",
        "            Args:\n",
        "              messages (List[Dict]): Message set of the current round\n",
        "              emissions (Dict): carbon footprint generated in the prediction\n",
        "              retries (int): number of calls on the server connection\n",
        "              backoff (float): time between retries\n",
        "        \"\"\"\n",
        "        decisions_run0 = {}\n",
        "        decisions_run1 = {}\n",
        "        decisions_run2 = {}\n",
        "        type_addiction_list = [\"betting\", \"onlinegaming\", \"betting\", \"trading\"]\n",
        "        type_addiction_decision = {}\n",
        "\n",
        "        # You must create the appropriate structure to send the predictions according to each task\n",
        "        for message in messages:\n",
        "            decisions_run0[message[\"nick\"]] = messages[\"run0_svm\"] # random.choice([0,1])\n",
        "            decisions_run1[message[\"nick\"]] = messages[\"run1_bert\"] # random.choice([0,1])\n",
        "            decisions_run2[message[\"nick\"]] = messages[\"run2_pipeline\"] # random.choice([0,1])\n",
        "            type_addiction_decision[message[\"nick\"]] = messages[\"type_addiction\"] # random.choice(type_addiction_list)\n",
        "\n",
        "        data1_run0 = {\n",
        "            \"predictions\": decisions_run0, \n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data1_run1 = {\n",
        "            \"predictions\": decisions_run1,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data1_run2 = {\n",
        "            \"predictions\": decisions_run2,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data2_run0 = {\n",
        "            \"predictions\": decisions_run0,\n",
        "            \"types\":type_addiction_decision,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data2_run1 = {\n",
        "            \"predictions\": decisions_run1,\n",
        "            \"types\":type_addiction_decision,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data2_run2 = {\n",
        "            \"predictions\": decisions_run2,\n",
        "            \"types\":type_addiction_decision,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "\n",
        "        data1 = []\n",
        "        data1.append(json.dumps(data1_run0))\n",
        "        data1.append(json.dumps(data1_run1))\n",
        "        data1.append(json.dumps(data1_run2))\n",
        "\n",
        "        data2 = []\n",
        "        data2.append(json.dumps(data2_run0))\n",
        "        data2.append(json.dumps(data2_run1))\n",
        "        data2.append(json.dumps(data2_run2))\n",
        "\n",
        "        # Session to POST request\n",
        "        session = requests.Session()\n",
        "        retries = Retry(\n",
        "                        total = retries,\n",
        "                        backoff_factor = backoff,\n",
        "                        status_forcelist = [500, 502, 503, 504]\n",
        "                        )\n",
        "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "        for run in range(0, self.number_of_runs):\n",
        "            # For each run, new decisions\n",
        "            response1 = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK='task1', TOKEN=self.token, RUN=run), json=[data1[run]]) # ENDPOINT\n",
        "            if response1.status_code != 200:\n",
        "                print(\"POST - Task1 - Status Code {} - Error: {}\".format(str(response1.status_code), str(response1.text)))\n",
        "                return\n",
        "            else:\n",
        "                print(\"POST - Task1 - run {} - Message: {}\".format(run, str(response1.text)))\n",
        "\n",
        "            response2 = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK='task2', TOKEN=self.token, RUN=run), json=[data2[run]]) # ENDPOINT\n",
        "            if response2.status_code != 200:\n",
        "                print(\"POST - Task2 - Status Code {} - Error: {}\".format(str(response2.status_code), str(response2.text)))\n",
        "                return\n",
        "            else:\n",
        "                print(\"POST - Task2 - run {} - Message: {}\".format(run, str(response2.text)))\n",
        "\n",
        "            with open('./data/preds/task1/round{}_run{}.json'.format(messages[0][\"round\"], run), 'w+', encoding='utf8') as json_file:\n",
        "                json.dump(data1[run], json_file, ensure_ascii=False)\n",
        "            with open('./data/preds/task2/round{}_run{}.json'.format(messages[0][\"round\"], run), 'w+', encoding='utf8') as json_file:\n",
        "                json.dump(data2[run], json_file, ensure_ascii=False)\n",
        "\n",
        "\n",
        "    def run_task1_2(self, retries: int, backoff: float):\n",
        "        \"\"\" Main thread\n",
        "            Args:\n",
        "              retries (int): number of calls on the server connection\n",
        "              backoff (float): time between retries\n",
        "        \"\"\"\n",
        "        # Get messages for task1_2\n",
        "        messages = self.get_messages(retries, backoff)\n",
        "\n",
        "        # If there are no messages\n",
        "        if len(messages) == 0:\n",
        "            print(\"All rounds processed\")\n",
        "            return\n",
        "\n",
        "        # list of messages per user\n",
        "        user_messages = {m[\"nick\"]: [m[\"message\"]] for m in messages}\n",
        "        round_count = 1\n",
        "        submitted = False\n",
        "\n",
        "        while len(messages) > 0:\n",
        "            print(messages)\n",
        "            print(\"----------------------- Processing round {}\".format(messages[0][\"round\"]))\n",
        "            # Save subjects\n",
        "            with open('./data/rounds/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n",
        "                json.dump(messages, json_file, ensure_ascii=False)\n",
        "\n",
        "\n",
        "            if round_count > 49:\n",
        "                # Calculate emissions for each prediction\n",
        "                self.tracker.start()\n",
        "\n",
        "                user_predictions = []\n",
        "                for user_id, user_messages_list in user_messages.items():\n",
        "                    user_input = user_document_to_input(user_messages_list, vectorizer_tfidf_task2)\n",
        "                    run0_svm = int(model_svm_task1.predict(user_input)[0])\n",
        "                    run1_bert = \n",
        "                    run2_pipeline = int(Pipeline().predict(user_input)[0])\n",
        "                    type_addiction = str(model_rf_task2.predict(user_input)[0])\n",
        "\n",
        "                    user_predictions.append(\n",
        "                        {\n",
        "                            \"round\": messages[0][\"round\"],\n",
        "                            \"nick\": user_id,\n",
        "                            \"run0_svm\": run0_svm,\n",
        "                            \"run1_bert\": run1_bert,\n",
        "                            \"run2_pipeline\": run2_pipeline,\n",
        "                            \"type_addiction\": type_addiction,\n",
        "                        }\n",
        "                    )\n",
        "                emissions = self.tracker.stop()\n",
        "\n",
        "                df = pd.read_csv(\"emissions.csv\")\n",
        "                measurements = df.iloc[-1][self.relevant_cols].to_dict()\n",
        "\n",
        "                # self.submit_decission(user_predictions, measurements, retries, backoff)\n",
        "                submitted = True\n",
        "                break\n",
        "\n",
        "            # One GET request for each round\n",
        "            messages = self.get_messages(retries, backoff)\n",
        "            round_count += 1\n",
        "\n",
        "            # accumulate next message\n",
        "            for message in messages:\n",
        "                user_messages[message[\"nick\"]].append(message[\"message\"])\n",
        "\n",
        "        if not submitted:\n",
        "            self.tracker.start()\n",
        "           \n",
        "            user_predictions = []\n",
        "            for user_id, user_messages_list in user_messages.items():\n",
        "                user_input = user_document_to_input(user_messages_list, vectorizer_tfidf_task2)\n",
        "                run0_svm = int(model_svm_task1.predict(user_input)[0])\n",
        "                run1_bert = \n",
        "                run2_pipeline = int(Pipeline().predict(user_input)[0])\n",
        "                type_addiction = str(model_rf_task2.predict(user_input)[0])\n",
        "\n",
        "                user_predictions.append(\n",
        "                    {\n",
        "                        \"round\": messages[0][\"round\"],\n",
        "                        \"nick\": user_id,\n",
        "                        \"run0_svm\": run0_svm,\n",
        "                        \"run1_bert\": run1_bert,\n",
        "                        \"run2_pipeline\": run2_pipeline,\n",
        "                        \"type_addiction\": type_addiction,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            emissions = self.tracker.stop()\n",
        "            df = pd.read_csv(\"emissions.csv\")\n",
        "            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n",
        "            # self.submit_decission(user_predictions, measurements, retries, backoff)\n",
        "            submitted = True\n",
        "\n",
        "        print(\"All rounds processed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMXuHLciXIO3"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GZrDpxNAS6-3"
      },
      "outputs": [],
      "source": [
        "def download_data(task: str, token: str):\n",
        "    download_messages_trial(task, token)\n",
        "    # download_messages_train(task, token)\n",
        "\n",
        "def get_post_data(task: str, token: str):\n",
        "    # Emissions Tracker Config\n",
        "    config = {\n",
        "        \"save_to_file\": True,\n",
        "        \"log_level\": \"WARNING\",\n",
        "        \"tracking_mode\": \"process\",\n",
        "        \"output_dir\": \".\",\n",
        "        \"allow_multiple_runs\": True\n",
        "    }\n",
        "    tracker = EmissionsTracker(**config)\n",
        "\n",
        "    number_runs = 3 # Max: 3\n",
        "\n",
        "    # Prediction period\n",
        "    client_task1_2 = Client_task1_2(task, token, number_runs, tracker)\n",
        "    client_task1_2.run_task1_2(5, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff6QgM3gErMm"
      },
      "source": [
        "Be careful! In this specific example we use the name of the task1 to do the get, knowing that it is the same data for both task 1 and task 2. In addition, the data upload is performed for both tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "aKMWQ5buS8OK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 21:13:40] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon WARNING @ 21:13:40] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Windows OS detected: Please install Intel Power Gadget to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 21:13:42] We saw that you have a 12th Gen Intel(R) Core(TM) i7-12800H but we don't know it. Please contact us.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'id_message': 123, 'round': 1, 'nick': 'subject1', 'message': '...', 'date': '...', 'platform': 'reddit'}, {'id_message': 134, 'round': 1, 'nick': 'subject10', 'message': '...', 'date': '...', 'platform': 'telegram'}, {'id_message': 134, 'round': 1, 'nick': 'subject103', 'message': '...', 'date': '...', 'platform': 'telegram'}, {'id_message': 134, 'round': 1, 'nick': 'subject101', 'message': '...', 'date': '...', 'platform': 'telegram'}]\n",
            "----------------------- Processing round 1\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/rounds/round1.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# download_data(\"task2\", TOKEN)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mget_post_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mTOKEN\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[22], line 20\u001b[0m, in \u001b[0;36mget_post_data\u001b[1;34m(task, token)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Prediction period\u001b[39;00m\n\u001b[0;32m     19\u001b[0m client_task1_2 \u001b[38;5;241m=\u001b[39m Client_task1_2(task, token, number_runs, tracker)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mclient_task1_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_task1_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[24], line 158\u001b[0m, in \u001b[0;36mClient_task1_2.run_task1_2\u001b[1;34m(self, retries, backoff)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------------- Processing round \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(messages[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Save subjects\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/rounds/round\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mround\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m    159\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(messages, json_file, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m round_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m49\u001b[39m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Calculate emissions for each prediction\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/rounds/round1.json'"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # download_data(\"task2\", TOKEN)\n",
        "    get_post_data(\"task1\",TOKEN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
