{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttODwCFd8K0Q"
      },
      "source": [
        "# Access the MentalRiskEs data and interact with the server\n",
        "\n",
        "This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes2025/) evaluation campaign at IberLEF 2025.\n",
        "\n",
        "**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes2025/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.\n",
        "\n",
        "**NOTE 2**: Along the code, please replace \"URL\" by the URL server and \"TOKEN\" by your personal token.\n",
        "\n",
        "Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DJN0pXx8W3-"
      },
      "source": [
        "# Install CodeCarbon package\n",
        "Read the [documentation](https://mlco2.github.io/codecarbon/) about the library if necessary. Remember that we provide a [CodeCarbon notebook](https://colab.research.google.com/drive/1boavnGOir0urui8qktbZaOmOV2pS5cn6?usp=sharing) with the example in its specific use in our competition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdvPWyc6x9cV",
        "outputId": "cf639de5-3041-46ef-8d19-5049e02dc0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
            "[notice] To update, run: C:\\Users\\maxi.rodriguez\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# !pip install codecarbon\n",
        "# !pip install dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqyN-7TcXbL8"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sqih7m6tN4MT"
      },
      "outputs": [],
      "source": [
        "import requests, zipfile, io\n",
        "from requests.adapters import HTTPAdapter, Retry\n",
        "from typing import List, Dict\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "from codecarbon import EmissionsTracker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHGGrr3GXdIb"
      },
      "source": [
        "# Endpoints\n",
        "These URL addresses are necessary for the connection to the server.\n",
        "\n",
        "**IMPORTANT:** Replace \"URL\" by the URL server and \"TOKEN\" by your user token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AdQPl8lbOKsg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://s3-ceatic.ujaen.es:8036 c461869975ffb0a7ba8544ffdddf3b58\n"
          ]
        }
      ],
      "source": [
        "load_dotenv()\n",
        "URL = os.getenv(\"SERVER_URL\")\n",
        "TOKEN = os.getenv(\"ACCESS_TOKEN\")\n",
        "print(URL, TOKEN)\n",
        "# Download endpoints\n",
        "ENDPOINT_DOWNLOAD_TRIAL = URL+\"/{TASK}/download_trial/{TOKEN}\"\n",
        "ENDPOINT_DOWNLOAD_TRAIN = URL+\"/{TASK}/download_train/{TOKEN}\"\n",
        "\n",
        "# Trial endpoints\n",
        "ENDPOINT_GET_MESSAGES_TRIAL = URL+\"/{TASK}/getmessages_trial/{TOKEN}\"\n",
        "ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"/{TASK}/submit_trial/{TOKEN}/{RUN}\"\n",
        "\n",
        "# Test endpoints\n",
        "ENDPOINT_GET_MESSAGES = URL+\"/{TASK}/getmessages/{TOKEN}\"\n",
        "ENDPOINT_SUBMIT_DECISIONS = URL+\"/{TASK}/submit/{TOKEN}/{RUN}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHNiyxHR5AJ"
      },
      "source": [
        "# Download Data\n",
        "To download the data, you can make use of the **function defined in the following**.\n",
        "\n",
        "The following function download the trial data. To adapt it to download the train and test data, follow the instructions given in the [website of the competition](https://sites.google.com/view/mentalriskes2024/evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Uaeh23C5R1lG"
      },
      "outputs": [],
      "source": [
        "def download_messages_trial(task: str, token: str):\n",
        "    \"\"\" Allows you to download the trial data of the task.\n",
        "        Args:\n",
        "          task (str): task from which the data is to be retrieved\n",
        "          token (str): authentication token\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.get(ENDPOINT_DOWNLOAD_TRIAL.format(TASK=task, TOKEN=token))\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
        "    else:\n",
        "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "      os.makedirs(\"./data/{task}/trial/\".format(task=task))\n",
        "      z.extractall(\"./data/{task}/trial/\".format(task=task))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v09j7ChSD6c-"
      },
      "outputs": [],
      "source": [
        "def download_messages_train(task: str, token: str):\n",
        "    \"\"\" Allows you to download the train data of the task.\n",
        "        Args:\n",
        "          task (str): task from which the data is to be retrieved\n",
        "          token (str): authentication token\n",
        "    \"\"\"\n",
        "    response = requests.get(ENDPOINT_DOWNLOAD_TRAIN.format(TASK=task, TOKEN=token))\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Train - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
        "    else:\n",
        "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "      os.makedirs(\"./data/{task}/train/\".format(task=task),exist_ok=True)\n",
        "      z.extractall(\"./data/{task}/train/\".format(task=task))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIqRCv3OS3Bn"
      },
      "source": [
        "# Client Server\n",
        "This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests.\n",
        "\n",
        "**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l0kONpltS2R9"
      },
      "outputs": [],
      "source": [
        "class Client_task1_2:\n",
        "    \"\"\" Client communicating with the official server.\n",
        "        Attributes:\n",
        "            token (str): authentication token\n",
        "            number_of_runs (int): number of systems. Must be 3 in order to advance to the next round.\n",
        "            tracker (EmissionsTracker): object to calculate the carbon footprint in prediction\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, task:str, token: str, number_of_runs: int, tracker: EmissionsTracker):\n",
        "        self.task = task\n",
        "        self.token = token\n",
        "        self.number_of_runs = number_of_runs\n",
        "        self.tracker = tracker\n",
        "        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy',\n",
        "                              'ram_energy','energy_consumed', 'cpu_count', 'gpu_count',\n",
        "                              'cpu_model', 'gpu_model', 'ram_total_size','country_iso_code']\n",
        "\n",
        "\n",
        "    def get_messages(self, retries: int, backoff: float) -> Dict:\n",
        "        \"\"\" Allows you to download the test data of the task by rounds.\n",
        "            Here a GET request is sent to the server to extract the data.\n",
        "            Args:\n",
        "              retries (int): number of calls on the server connection\n",
        "              backoff (float): time between retries\n",
        "        \"\"\"\n",
        "        session = requests.Session()\n",
        "        retries = Retry(\n",
        "                        total = retries,\n",
        "                        backoff_factor = backoff,\n",
        "                        status_forcelist = [500, 502, 503, 504]\n",
        "                        )\n",
        "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token)) # ENDPOINT\n",
        "\n",
        "        if response.status_code != 200:\n",
        "          print(\"GET - Task {} - Status Code {} - Error: {}\".format(self.task, str(response.status_code), str(response.text)))\n",
        "          return []\n",
        "        else:\n",
        "          return json.loads(response.content)\n",
        "\n",
        "    def submit_decission(self, messages: List[Dict], emissions: Dict, retries: int, backoff: float):\n",
        "        \"\"\" Allows you to submit the decisions of the task by rounds.\n",
        "            The POST requests are sent to the server to send predictions and carbon emission data\n",
        "            Args:\n",
        "              messages (List[Dict]): Message set of the current round\n",
        "              emissions (Dict): carbon footprint generated in the prediction\n",
        "              retries (int): number of calls on the server connection\n",
        "              backoff (float): time between retries\n",
        "        \"\"\"\n",
        "        decisions_run0 = {}\n",
        "        decisions_run1 = {}\n",
        "        decisions_run2 = {}\n",
        "        type_addiction_list = [\"betting\", \"onlinegaming\", \"betting\", \"trading\"]\n",
        "        type_addiction_decision = {}\n",
        "\n",
        "        # You must create the appropriate structure to send the predictions according to each task\n",
        "        for message in messages:\n",
        "            decisions_run0[message[\"nick\"]] = random.choice([0,1])\n",
        "            decisions_run1[message[\"nick\"]] = random.choice([0,1])\n",
        "            decisions_run2[message[\"nick\"]] = random.choice([0,1])\n",
        "            type_addiction_decision[message[\"nick\"]] = random.choice(type_addiction_list)\n",
        "\n",
        "        data1_run0 = {\n",
        "            \"predictions\": decisions_run0,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data1_run1 = {\n",
        "            \"predictions\": decisions_run1,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data1_run2 = {\n",
        "            \"predictions\": decisions_run2,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data2_run0 = {\n",
        "            \"predictions\": decisions_run0,\n",
        "            \"types\":type_addiction_decision,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data2_run1 = {\n",
        "            \"predictions\": decisions_run1,\n",
        "            \"types\":type_addiction_decision,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "        data2_run2 = {\n",
        "            \"predictions\": decisions_run2,\n",
        "            \"types\":type_addiction_decision,\n",
        "            \"emissions\": emissions\n",
        "        }\n",
        "\n",
        "        data1 = []\n",
        "        data1.append(json.dumps(data1_run0))\n",
        "        data1.append(json.dumps(data1_run1))\n",
        "        data1.append(json.dumps(data1_run2))\n",
        "\n",
        "        data2 = []\n",
        "        data2.append(json.dumps(data2_run0))\n",
        "        data2.append(json.dumps(data2_run1))\n",
        "        data2.append(json.dumps(data2_run2))\n",
        "\n",
        "        # Session to POST request\n",
        "        session = requests.Session()\n",
        "        retries = Retry(\n",
        "                        total = retries,\n",
        "                        backoff_factor = backoff,\n",
        "                        status_forcelist = [500, 502, 503, 504]\n",
        "                        )\n",
        "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "        for run in range(0, self.number_of_runs):\n",
        "            # For each run, new decisions\n",
        "            response1 = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK='task1', TOKEN=self.token, RUN=run), json=[data1[run]]) # ENDPOINT\n",
        "            if response1.status_code != 200:\n",
        "                print(\"POST - Task1 - Status Code {} - Error: {}\".format(str(response1.status_code), str(response1.text)))\n",
        "                return\n",
        "            else:\n",
        "                print(\"POST - Task1 - run {} - Message: {}\".format(run, str(response1.text)))\n",
        "\n",
        "            response2 = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK='task2', TOKEN=self.token, RUN=run), json=[data2[run]]) # ENDPOINT\n",
        "            if response2.status_code != 200:\n",
        "                print(\"POST - Task2 - Status Code {} - Error: {}\".format(str(response2.status_code), str(response2.text)))\n",
        "                return\n",
        "            else:\n",
        "                print(\"POST - Task2 - run {} - Message: {}\".format(run, str(response2.text)))\n",
        "\n",
        "            with open('./data/preds/task1/round{}_run{}.json'.format(messages[0][\"round\"], run), 'w+', encoding='utf8') as json_file:\n",
        "                json.dump(data1[run], json_file, ensure_ascii=False)\n",
        "            with open('./data/preds/task2/round{}_run{}.json'.format(messages[0][\"round\"], run), 'w+', encoding='utf8') as json_file:\n",
        "                json.dump(data2[run], json_file, ensure_ascii=False)\n",
        "\n",
        "\n",
        "    def run_task1_2(self, retries: int, backoff: float):\n",
        "        \"\"\" Main thread\n",
        "            Args:\n",
        "              retries (int): number of calls on the server connection\n",
        "              backoff (float): time between retries\n",
        "        \"\"\"\n",
        "        # Get messages for task1_2\n",
        "        messages = self.get_messages(retries, backoff)\n",
        "\n",
        "        # If there are no messages\n",
        "        if len(messages) == 0:\n",
        "            print(\"All rounds processed\")\n",
        "            return\n",
        "\n",
        "        while len(messages) > 0:\n",
        "            print(messages)\n",
        "            print(\"----------------------- Processing round {}\".format(messages[0][\"round\"]))\n",
        "            # Save subjects\n",
        "            with open('./data/rounds/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n",
        "                json.dump(messages, json_file, ensure_ascii=False)\n",
        "\n",
        "            # Calculate emissions for each prediction\n",
        "            self.tracker.start()\n",
        "\n",
        "            # Your code\n",
        "\n",
        "            emissions = self.tracker.stop()\n",
        "            df = pd.read_csv(\"emissions.csv\")\n",
        "            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n",
        "\n",
        "            self.submit_decission(messages, measurements, retries, backoff)\n",
        "\n",
        "            # One GET request for each round\n",
        "            messages = self.get_messages(retries, backoff)\n",
        "\n",
        "        print(\"All rounds processed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMXuHLciXIO3"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GZrDpxNAS6-3"
      },
      "outputs": [],
      "source": [
        "def download_data(task: str, token: str):\n",
        "    # download_messages_trial(task, token)\n",
        "    download_messages_train(task, token)\n",
        "\n",
        "def get_post_data(task: str, token: str):\n",
        "    # Emissions Tracker Config\n",
        "    config = {\n",
        "        \"save_to_file\": True,\n",
        "        \"log_level\": \"WARNING\",\n",
        "        \"tracking_mode\": \"process\",\n",
        "        \"output_dir\": \".\",\n",
        "        \"allow_multiple_runs\": True\n",
        "    }\n",
        "    tracker = EmissionsTracker(**config)\n",
        "\n",
        "    number_runs = 3 # Max: 3\n",
        "\n",
        "    # Prediction period\n",
        "    client_task1_2 = Client_task1_2(task, token, number_runs, tracker)\n",
        "    client_task1_2.run_task1_2(5, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff6QgM3gErMm"
      },
      "source": [
        "Be careful! In this specific example we use the name of the task1 to do the get, knowing that it is the same data for both task 1 and task 2. In addition, the data upload is performed for both tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aKMWQ5buS8OK"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    download_data(\"task1\", TOKEN)\n",
        "    # get_post_data(\"task1\",TOKEN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
